#!/usr/bin/env python3
"""
Quick validation test of the enhanced Monte Carlo system
"""

import pandas as pd
import numpy as np

print("ðŸŽ² Quick Validation of Enhanced Monte Carlo System")
print("=" * 60)

print("âœ… Testing individual components...")

# Simulate uncertainty calculation
print("\n1. Testing uncertainty calculation...")
data_quality = {'completeness': 0.85, 'sample_size': 15, 'weather_penalty': 0.1}
track_category = 'medium'

# Basic uncertainty factors
completeness_factor = 2.0 - data_quality['completeness']  # 1.15
sample_size_factor = max(0.5, min(2.0, 25 / data_quality['sample_size']))  # 1.67
track_factor = 1.0  # medium track
weather_factor = 1.0 + (data_quality['weather_penalty'] * 2.0)  # 1.2

position_uncertainty = np.sqrt(completeness_factor * sample_size_factor * track_factor * weather_factor)

print(f"   Data completeness factor: {completeness_factor:.2f}")
print(f"   Sample size factor: {sample_size_factor:.2f}")
print(f"   Weather factor: {weather_factor:.2f}")
print(f"   Combined position uncertainty: {position_uncertainty:.2f}x")

# Test different track categories
print("\n2. Testing track-specific uncertainty...")
track_uncertainties = {
    'very_low': 0.6,    # Monaco - very predictable
    'low': 0.8,         # Spain - somewhat predictable 
    'medium': 1.0,      # Canada - balanced
    'high': 1.3,        # Austria - more unpredictable
    'very_high': 1.6    # Bahrain - chaotic
}

for track, factor in track_uncertainties.items():
    track_position_uncertainty = np.sqrt(completeness_factor * sample_size_factor * factor * weather_factor)
    print(f"   {track:10}: {track_position_uncertainty:.2f}x uncertainty")

# Test Monte Carlo simulation logic
print("\n3. Testing Monte Carlo simulation logic...")
race_predictions = pd.DataFrame({
    'Driver': ['VER', 'HAM', 'LEC', 'NOR', 'PIA'],
    'Predicted_Finish': [1, 3, 5, 2, 4],
    'DNF_Risk': [5.0, 8.0, 12.0, 6.0, 10.0]
})

num_simulations = 200  # Small number for quick test
simulation_results = []

for sim in range(num_simulations):
    sim_result = race_predictions.copy()
    
    for idx, row in sim_result.iterrows():
        predicted_pos = row['Predicted_Finish']
        dnf_prob = row['DNF_Risk'] / 100
        
        # Apply uncertainty (simplified version)
        position_std = 2.0 * position_uncertainty  # Base 2.0 position std dev
        position_variation = np.random.normal(0, position_std)
        
        # DNF simulation
        if np.random.random() < dnf_prob:
            final_pos = 99  # DNF
        else:
            final_pos = max(1, min(20, predicted_pos + position_variation))
        
        sim_result.loc[idx, 'Final_Position'] = final_pos
    
    # Re-rank finished drivers
    finished = sim_result[sim_result['Final_Position'] < 99].copy()
    if len(finished) > 0:
        finished = finished.sort_values('Final_Position')
        for i, idx in enumerate(finished.index):
            sim_result.loc[idx, 'Final_Position'] = i + 1
    
    simulation_results.append(sim_result[['Driver', 'Final_Position']].copy())

# Aggregate results
print("âœ… Monte Carlo simulation completed!")
summary_data = []

for driver in race_predictions['Driver']:
    positions = []
    dnfs = 0
    
    for sim_result in simulation_results:
        driver_result = sim_result[sim_result['Driver'] == driver]
        if len(driver_result) > 0:
            pos = driver_result['Final_Position'].iloc[0]
            if pos == 99:
                dnfs += 1
            else:
                positions.append(pos)
    
    if positions:
        avg_pos = np.mean(positions)
        p1_prob = (np.array(positions) == 1).sum() / num_simulations * 100
        dnf_rate = dnfs / num_simulations * 100
        
        summary_data.append({
            'Driver': driver,
            'Original_Pred': race_predictions[race_predictions['Driver'] == driver]['Predicted_Finish'].iloc[0],
            'Avg_Position': avg_pos,
            'P1_Prob': p1_prob,
            'DNF_Rate': dnf_rate
        })

# Display results
print("\nðŸ“Š Monte Carlo Results:")
print("-" * 60)
print(f"{'Driver':<8} {'Original':<10} {'MC Avg':<10} {'Win%':<8} {'DNF%':<8}")
print("-" * 60)

summary_df = pd.DataFrame(summary_data).sort_values('Avg_Position')
for _, row in summary_df.iterrows():
    print(f"{row['Driver']:<8} P{row['Original_Pred']:<9.0f} {row['Avg_Position']:<10.1f} "
          f"{row['P1_Prob']:<8.1f} {row['DNF_Rate']:<8.1f}")

print("\nâœ… Enhanced Monte Carlo validation complete!")
print(f"ðŸŽ¯ Uncertainty scaling factor: {position_uncertainty:.2f}x base randomness")
print(f"ðŸ“Š Results show realistic position changes from predictions")
print(f"ðŸŽ² System ready for full race simulations!")
